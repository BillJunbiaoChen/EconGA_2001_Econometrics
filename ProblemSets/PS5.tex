\documentclass[11pt]{article}

%%METADATA
\title{GA2001 Econometrics \\Solution to Problem Set 5}
\author{
Junbiao Chen\thanks{E-mail: jc14076@nyu.edu.}
}
\date{\today}


%%PACKAGES
\usepackage{mdframed} % For boxed environments
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{tabularx}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{amsmath,amsthm,amssymb}
\usepackage[hyphens]{url}
\usepackage{natbib}
\usepackage[font=normalsize,labelfont=bf]{caption}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{colorlinks=true,urlcolor=blue,citecolor=blue}
\usepackage{stmaryrd}  %Package with \boxast command
\usepackage{enumerate}% http://ctan.org/pkg/enumerate %Supports lowercase Roman-letter enumeration
\usepackage{verbatim} %Package with \begin{comment} environment
%\usepackage{enumitem}
\usepackage{physics}
\usepackage{tikz}
\usepackage{listings}
\usepackage{upquote}
\usepackage{booktabs} %Package with \toprule and \bottomrule
\usepackage{etoc}     %Package with \localtableofcontents
\usepackage{placeins}    %Package that prevent repositioning the tables
\usepackage{multicol}
\usepackage{bm}
\usepackage{subfig}
\usepackage{csquotes}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{language=bash,
  frame=tb,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=false,
  tabsize=3
}

\lstset{language=C,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=false,
  tabsize=4
}

\definecolor{lightblue}{rgb}{0.68, 0.85, 0.9} %

%CUSTOM DEFINITIONS
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem*{remark}{Remark}
\setcounter{secnumdepth}{3}
\usepackage{tikz}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{automata, positioning, arrows, calc}

\tikzset{
	->,  % makes the edges directed
	>=stealth, % makes the arrow heads bold
	shorten >=2pt, shorten <=2pt, % shorten the arrow
	node distance=3cm, % specifies the minimum distance between two nodes. Change if n
	every state/.style={draw=blue!55,very thick,fill=blue!20}, % sets the properties for each ’state’ n
	initial text=$ $, % sets the text that appears on the start arrow
 }

%% PROPOSITION
% Define the Proposition environment
\newmdenv[
  innerleftmargin=10pt, 
  innerrightmargin=10pt,
  innertopmargin=10pt,
  innerbottommargin=10pt,
  linecolor=black, 
  linewidth=1pt,
  backgroundcolor=white, 
  roundcorner=5pt
]{propositionbox}

\newtheoremstyle{boldtitle} % Define a new theorem style
  {10pt} % Space above
  {10pt} % Space below
  {\itshape} % Body font
  {} % Indent amount
  {\bfseries} % Theorem head font
  {.} % Punctuation after theorem head
  { } % Space after theorem head
  {} % Theorem head spec

\theoremstyle{boldtitle} % Use the custom style
\newtheorem{proposition}{Proposition} % Define the proposition environment

% Redefine the proposition environment to use the box
\newenvironment{boxedproposition}[1][]
{\begin{propositionbox}\begin{proposition}[#1]}
{\end{proposition}\end{propositionbox}}

%%FORMATTING
\usepackage[bottom]{footmisc}
\onehalfspacing
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}
\bibliographystyle{../bib/aeanobold-oxford}


%main text
\begin{document}
\maketitle
\section*{Problem 1.}
\paragraph{1. Solution}
The probability limit of the OLS estimator $\hat{\beta}_n$ is 
\[
\beta_* = \left(\mathbb{E}[XX']\right)^{-1}\mathbb{E}[XY]
\]

\paragraph{2. Solution}
If we have more parameters than observations,
we can perfectly fit the data and achieves an $R^2=1.0$,
which further leads to an over-fitting issue.

\paragraph{3. Solution}
Given data $\{x_1, x_2, \dots, x_n \}$,
define 
\begin{align*}
\Psi(X) = \begin{bmatrix}
    x_1 & x_1^2 & \dots & x_1^k \\ 
    x_2 & x_2^2 & \dots & x_2^k \\ 
    \vdots \\
    x_n & x_n^2 & \dots & x_n^k \\ 
\end{bmatrix}
\end{align*}
As such, the estimator of a polynomial regression is given by 
\[
\tilde{\beta}_n = \left( X'X\right)^{-1}X'Y
\]
Therefore, the conditional variance is given by 
\begin{align*}
\text{Var}\left(\tilde{\beta}_n |X_1, \dots, X_n \right) & = \text{Var}[\left( X'X\right)^{-1}X'Y|X] \\ 
 & = \left( X'X\right)^{-1}X' \text{Var}[Y|X] (\left( X'X\right)^{-1}X')' \\ 
 & = \sigma^2  \left( X'X\right)^{-1}X'X \left( X'X\right)^{-1} \\
 & = \sigma^2  \left( X'X\right)^{-1}
\end{align*}

\section*{Problem 2.}
\paragraph{1. Solution} Given the data $\{Y_i, X_i\}_{i=1}^n$, the likelihood is given by 
\[
L = \prod_{i=1} \left(
    \frac{\exp (X_i'\theta)}{1 + \exp (X_i'\theta)}
\right)^{Y_i} 
\left(
    \frac{1}{1 + \exp (X_i'\theta)}
\right)^{1 - Y_i} 
\]
It follows that the log-likelihood is given by 
\[
\ln L = \sum_{i=1} Y_i X_i'\theta - \ln(1 + \exp (X_i'\theta))
\]
Thus, 
\[
Q_n = \frac{1}{n} \sum_{i=1} Y_i X_i'\theta - \ln\bigg[1 + \exp (X_i'\theta)\bigg]
\]


\paragraph{2. Solution} 
The score is given by 
\[
S(\theta) = \frac{\partial Q_n}{\partial \theta} = \sum_i Y_i X_i - \left[ 1 + \exp(X_i'\theta) \right]^{-1} X_i,
\]
which is a $k \times 1$ vector (assuming $\theta \in \mathbb{R}^{k}$.)
And Hessian is given by 
\begin{align*}
H(\theta) & = \frac{\partial^2 \ln L}{\partial \theta \partial \theta'}  \\ 
    & = \sum_i \frac{X_i \exp (X_i'\theta)X_i'}{(1 + \exp(X_i \theta))^2},
\end{align*}
which is a $k \times k$ matrix. 

\paragraph{3. Solution} 
Under correctly specified model, 
\[
\mathbb{E}[Y|X] = \frac{\exp(X'\theta_0)}{1 + \exp(X'\theta_0)}
\]
Thus, 
\[
Q_\infty(\theta) = \mathbb{E}\left[YX'\theta \right] - \mathbb{E}[\ln(1+ \exp(X'\theta))]
\]
By the Law of Iterated Expectation, we have 
\begin{align*}
\mathbb{E}[YX'\theta] & = \mathbb{E}[\mathbb{E}[YX'\theta|X]] \\ 
    & = \mathbb{E}\bigg[\mathbb{E}[Y|X]X'\theta\bigg] \\ 
    & = \mathbb{E}\bigg[\frac{\exp(X'\theta_0)}{1 + \exp(X'\theta_0)}X'\theta\bigg] 
\end{align*}
Therefore, 
\[
Q_\infty(\theta) = \mathbb{E}\bigg[\frac{\exp(X'\theta_0)}{1 + \exp(X'\theta_0)}X'\theta - \ln \bigg(1 + \exp(X'\theta) \bigg)\bigg] 
\]


\paragraph{4. Solution} 
% Recall that the separation condition says 
% \[
% \sup_{\theta \in \Theta \cup \mathcal{N}^c} Q_\infty (\theta) < Q_\infty (\theta_*)
% \]
% for any neighborhood  $\mathcal{N}$ of $\theta_*$.
Recall that the Lemma on page 28 of the lecture:

\noindent \textbf{Lemma}: Suppose (i) $\theta$ is compact, (ii) $Q_\infty$ is continuous on $\theta$, 
and (iii) Identification: $\theta_*$ is the unique maximizer of $Q_\infty$ on $\theta$,
then the separation condition is satisfied. 
\vspace{-3mm}
\paragraph{Proof} Since $\theta \in \mathbb{R}^k$, it is compact. 
(ii) By a convergence-argument, we would have the continuity of $Q_\infty$.
(iii) By the Lemma on page 34 of the lecture notes, we note that 
If $\{f(\dot | \dot; \theta: \theta \in \Theta)\}$ is correctly specified and one-to-one parameterized,
then $\theta_0$ is the unique solution.
Thus, the separation condition is well-established.

% Thus, we want to show 
% \[
% \sup_{\theta \in \Theta \cup \mathcal{N}^c} Q_\infty (\theta) < Q_\infty(\theta_*) = \mathbb{E}\bigg[\frac{\exp(X'\theta_0)}{1 + \exp(X'\theta_0)}X'\theta_* - \ln \bigg(1 + \exp(X'\theta_*) \bigg)\bigg] 
% \]
% for any neighborhood  $\mathcal{N}$ of $\theta_*$.

\paragraph{5. Solution}

The Maximum Likelihood Estimator is given by
\[
\hat{\theta}_n = \arg\max_{\theta \in \Theta} Q_n(\theta).
\]
Therefore, we have
\[
Q_n(\hat{\theta}_n) \geq Q_n(\theta_0).
\]
It follows that
\[
Q_n(\theta_0) - Q_n(\hat{\theta}_n) \leq 0.
\]
Let $\delta_n = \sup_{\theta \in \Theta} |Q_\infty(\theta) - Q_n(\theta)|$.  
Since $Q_n(\hat{\theta}_n) \geq Q_n(\theta_0)$,
and $Q_n(\theta_0) \geq Q_\infty(\theta_0) - \delta_n$,
we have
\[
Q_\infty(\theta_0) - \delta_n \leq Q_n(\hat{\theta}_n) \leq Q_\infty(\hat{\theta}_n) + \delta_n.
\]
Rearranging terms, we get:
\[
Q_\infty(\theta_0) - \delta_n \leq Q_\infty(\hat{\theta}_n) + \delta_n.
\]

\paragraph{6. Solution}
Based on the Master Asymptotic Normality Theorem, 
the asymptotic distribution of the MLE is 
\[
\sqrt{n}(\hat{\theta}_n - \theta_0) \xrightarrow{d} \mathcal{N}(0, V),
\]
where the asymptotic variance $V$ is the inverse of the Fisher Information matrix. 
The null hypothesis is given by $H_0: \theta_{0,2} = \dots = \theta_{0,k} = 0$. 
Under the null hypothesis, 
we can construct a Wald statistic $W$ that follows a $\chi^2$-distribution. 
We reject the null hypothesis if the calculated $W$ statistic 
exceeds the critical value from the $\chi^2$ distribution.

\bibliography{../bib/notes.bib}

\end{document}