\documentclass[11pt]{article}

%%METADATA
\title{GA2001 Econometrics \\Solution to Problem Set 3}
\author{
Junbiao Chen\thanks{E-mail: jc14076@nyu.edu.}
}
\date{\today}


%%PACKAGES
\usepackage{mdframed} % For boxed environments
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{tabularx}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{amsmath,amsthm,amssymb}
\usepackage[hyphens]{url}
\usepackage{natbib}
\usepackage[font=normalsize,labelfont=bf]{caption}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{colorlinks=true,urlcolor=blue,citecolor=blue}
\usepackage{stmaryrd}  %Package with \boxast command
\usepackage{enumerate}% http://ctan.org/pkg/enumerate %Supports lowercase Roman-letter enumeration
\usepackage{verbatim} %Package with \begin{comment} environment
%\usepackage{enumitem}
\usepackage{physics}
\usepackage{tikz}
\usepackage{listings}
\usepackage{upquote}
\usepackage{booktabs} %Package with \toprule and \bottomrule
\usepackage{etoc}     %Package with \localtableofcontents
\usepackage{placeins}    %Package that prevent repositioning the tables
\usepackage{multicol}
\usepackage{bm}
\usepackage{subfig}
\usepackage{csquotes}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{language=bash,
  frame=tb,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=false,
  tabsize=3
}

\lstset{language=C,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=false,
  tabsize=4
}

\definecolor{lightblue}{rgb}{0.68, 0.85, 0.9} %

%CUSTOM DEFINITIONS
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem*{remark}{Remark}
\setcounter{secnumdepth}{3}
\usepackage{tikz}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{automata, positioning, arrows, calc}

\tikzset{
	->,  % makes the edges directed
	>=stealth, % makes the arrow heads bold
	shorten >=2pt, shorten <=2pt, % shorten the arrow
	node distance=3cm, % specifies the minimum distance between two nodes. Change if n
	every state/.style={draw=blue!55,very thick,fill=blue!20}, % sets the properties for each ’state’ n
	initial text=$ $, % sets the text that appears on the start arrow
 }

%% PROPOSITION
% Define the Proposition environment
\newmdenv[
  innerleftmargin=10pt, 
  innerrightmargin=10pt,
  innertopmargin=10pt,
  innerbottommargin=10pt,
  linecolor=black, 
  linewidth=1pt,
  backgroundcolor=white, 
  roundcorner=5pt
]{propositionbox}

\newtheoremstyle{boldtitle} % Define a new theorem style
  {10pt} % Space above
  {10pt} % Space below
  {\itshape} % Body font
  {} % Indent amount
  {\bfseries} % Theorem head font
  {.} % Punctuation after theorem head
  { } % Space after theorem head
  {} % Theorem head spec

\theoremstyle{boldtitle} % Use the custom style
\newtheorem{proposition}{Proposition} % Define the proposition environment

% Redefine the proposition environment to use the box
\newenvironment{boxedproposition}[1][]
{\begin{propositionbox}\begin{proposition}[#1]}
{\end{proposition}\end{propositionbox}}

%%FORMATTING
\usepackage[bottom]{footmisc}
\onehalfspacing
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}
\bibliographystyle{../bib/aeanobold-oxford}


%main text
\begin{document}
\maketitle
\section*{Problem 1.}
\paragraph{1.} Since we have proved $X = 0 \text{a.s.} \Rightarrow \mathbb{E} X = 0$ in our recitation.
I only need to prove that 
\[
\mathbb{E}X = 0 \Rightarrow X = 0 \text{ a.s.}
\]
\vspace{-3mm}
\noindent (Roadmap: I will use Markov inequality to show that $\mathbb{E}X = 0 \Rightarrow X = 0 \text{ a.s.}$.)
\paragraph{Proof} For any $\epsilon > 0$, by Markov inequality, we have
\[
\mathbb{P}(|X| > 0) \leq \frac{\mathbb{E}|X|}{\epsilon} \text{ for any } \epsilon > 0
\]
Since $\mathbb{E}X = 0$, we have $\mathbb{E}|X| = 0$.
Notice that $\mathbb{P}(X > 0) = \bigcup_{n=1}^\infty \mathbb{P}(|X| > \frac{1}{n})$,
we have
\[\mathbb{P}(X > 0) \leq \sum_{n=1}^\infty \mathbb{P}(|X| > \frac{1}{n}) \leq 0\]
% Similarly, we can show that $\mathbb{P}(X < 0) = 0$.
Therefore, we conclude that $\mathbb{P}(X > 0) = 0$ and thus $X = 0 \text{ a.s.}$
\(\blacksquare\)


\paragraph{2.} Consider a random variable that maps ``Head'' and ``Tail'' to 
$Y = 1$ and $Y= -1$ respectively.
We have $\mathbb{E}Y = 0$, but $Y \neq 0$ everywhere. 
Therefore, the claim ``$X = 0 \text{ a.s. } \Leftrightarrow \mathbb{E}X = 0$'' fails 
if $X$ includes both positive and negative values.

% \paragraph{3.}




\section*{Problem 2.}
\paragraph{1.} Since $f(\cdot, \theta)$ is $\mu-$integrable, we have that $f(\omega, \theta_n)$ and  $f(\omega, \theta_0)$ are measurable.
Since $f g$ are measurable if $f$ and $g$ are measurable, 
we can conclude that $f'_n(\omega) = \frac{f(\omega, \theta_n) - f(\omega, \theta_0)}{\theta_n - \theta_0}$ is measurable. \(\blacksquare\)

\paragraph{2.} Since $f_n'$ is measurable for each $n$, and we know that \textbf{measurability is preserved by limiting operations on sequences of functions}.
Therefore, $\frac{\partial f(\cdot, \theta_0)}{\partial \theta} = \lim_{n \to \infty} f_n'(\omega)$ is measurable. \(\blacksquare\)

Since $g$ is $\mu-$integrable, by Dominated Convergence Theorem, we have 
$\frac{\partial f(\cdot, \theta_0)}{\partial \theta}$ is $\mu-$integrable. \(\blacksquare\)

\paragraph{3.} 
(Roadmap: I will use Intermediate Value Theorem to prove this part.)
\paragraph{Proof} Since $f(\omega, \cdot)$ is differentiable for each $\omega$,
by Intermediate Value Theorem, there exists $\theta_n^* \in [\theta_0, \theta_n]$ such that
\[
\frac{f(\omega, \theta_n) - f(\omega, \theta_0 )}{\theta_n - \theta_0} 
= \frac{\partial f(\omega, \theta_n^*)}{\partial \theta}
\]
By Assumption A.3, we complete the proof that $|f_n'| < g$ for every $n$. \(\blacksquare\)


\paragraph{4.}
From part 3, we showed that 
\[
\frac{h(\theta_n) - h(\theta_0)}{\theta_n - \theta_0} = \int_\Omega f_n'(\omega) d \mu (\omega)
\]
It follows that
\[
\frac{dh(\theta_0)}{d \theta} = \lim_{n \rightarrow \infty} \int_\Omega f_n'(\omega) d \mu (\omega)
\]
By Dominated Convergence Theorem (here I use the result from part 3 that $|f_n'| < g$ for every $n$), we have 
\[
\frac{dh(\theta_0)}{d \theta} = \int_\Omega \lim_{n \rightarrow \infty} f_n'(\omega) d \mu (\omega)
\]
As a result, we conclude that
\[
\frac{dh(\theta_0)}{d \theta} = \int_\Omega \frac{\partial f(\omega, \theta_0)}{\partial \theta} d \mu (\omega)
\]. \(\blacksquare\)


\section*{Problem 3.}
\paragraph{1.} 
\begin{align*}
    \int_{[0,\infty)}\mathbb{P}\{ X > t \} d \lambda(t) & = \int_{\mathbb{R}} \mathbb{P}\{ X > t \} \bm{1}_{[0,\infty)}(t) d \lambda(t) \\ 
    & = \int_{\mathbb{R}} \left[ \int_\Omega \bm{1}_{(\omega, t): X(\omega) \geq t \geq 0}(\omega, t) d \mathbb{P}(\omega) \right] d \lambda(t)
\end{align*}
where the second equality uses the definition of $\mathbb{P}(X > t) = \int_\Omega \bm{1}_{{X(\omega) > t}} d\mathbb{P}(\omega)$.

\paragraph{2.} 
Per Fubini's theorem, the integrals of $\int_{\mathbb{R}} \left[ \int_\Omega \bm{1}_{(\omega, t): X(\omega) \geq t \geq 0}(\omega, t) d \mathbb{P}(\omega) \right] d \lambda(t)$
are inter-changable.

\paragraph{3.} 
For fixed $\omega$, we have 
\[
\int_{\mathbb{R}} \bm{1}_{(\omega, t): X(\omega) \geq t \geq 0}(\omega, t) d \lambda (t) = \int_0^{X(\omega)} 1 d \lambda(t) = X(\omega)
\]
Therefore, we can complete the proof by showing that 
\[
\int_{\mathbb{R}} \left[ \int_\Omega \bm{1}_{(\omega, t): X(\omega) \geq t \geq 0}(\omega, t) d \mathbb{P}(\omega) \right] d \lambda(t) = \int_\Omega X(\omega) d \mathbb{P}(\omega) = \mathbb{E}X
\]


\paragraph{4.} 
Note that for a function (in this case, a random variable), we can decompose it into its positive and negative parts.
\[
f = f^+ - f^- \quad \text{ where } f^+ = \max\{f, 0\} \text{ and } f^- = \max\{-f, 0\}
\]
Therefore, we have
\[
\mathbb{E}(Y) = \mathbb{E}(Y^+) - \mathbb{E}(Y^-) = \int_0^\infty \mathbb{P}\{ Y^+ > t \} d\lambda(t) - \int_0^\infty \mathbb{P}\{ Y^- > t \} d\lambda(t)
\]
\(\blacksquare\)

\section*{Problem 4.}
\paragraph{1.} Define a sequence of function $f_i: \mathbb{R} \rightarrow [0, \infty)$ as follow:
\begin{align}
    f_i(x) =
    \begin{cases}
    f(x), & x \in [0, i] \\
    0, & \text{otherwise}
    \end{cases}
\end{align}
Clearly, $f_i(x) \leq f_{i+1}(x)$ for all $x \in \mathbb{R}$.

For each $f_i: \mathbb{N} \rightarrow [0, \infty)$, 
we can represent its integral with respect to counting measure using simple functions:
\begin{equation}
    \int_\Omega f_i(\omega) d\mu(\omega) = \left(\sum_{k=1}^i f_i(k) \mu_c(k) \right) + \left(\sum_{k=i+1}^\infty f_i(k) \mu_c(k) \right) = \sum_{k=1}^i f_i(k)
\end{equation}
\textbf{Note:} The counting measure $\mu_c(k) = 1$ for all $k \in \mathbb{N}$.

Then, applying Monotone Convergence Theorem, we have    
\begin{equation}
    \int_\Omega f(\omega) d\mu(\omega) = \lim_{i \to \infty} \int_\Omega f_i(\omega) d\mu(\omega) = \lim_{i \to \infty} \sum_{k=1}^i f_i(k) = \sum_{k=1}^\infty f(k)
\end{equation}
\(\blacksquare\)


\paragraph{2.} Following the result of part 1, we have the following relation in $\mathbb{N}^2$:
\[
\int_{\mathbb{N}^2} f d\mu(\omega) = \sum_{(m,n) \in \mathbb{N}^2} f(m,n)
\]
which is equivalent to both 
\[
\sum_{m \in \mathbb{N}} \sum_{n \in \mathbb{N}}  a_{mn} 
\quad \text{ and } \quad
 \sum_{n \in \mathbb{N}} \sum_{m \in \mathbb{N}} a_{mn}
\]
Replacing $f(m,n)$ with $a_{mn}$, then we finished the proof. \(\blacksquare\)


\bibliography{../bib/notes.bib}

\end{document}